---
title: "Lab 2"
author: "Damian Ke & Kyriakos Papadopoulos"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 2. Decision trees and logistic regression for bank marketing

## Question 1: 
Import the data to R, remove variable “duration” and divide into
training/validation/test as 40/30/30: use data partitioning code specified in
Lecture 2a.

```{r}
data = read.csv2("bank-full.csv",stringsAsFactors = TRUE)
#2.1
data = subset(data, select = -c(duration))
n <- dim(data)[1]
set.seed(12345)
id <- sample(1:n, floor(n*0.4)) 
train <- data[id,] 

id1 <- setdiff(1:n, id)
set.seed(12345)
id2 <- sample(id1, floor(n*0.3)) 
validation <- data[id2,]

id3 <- setdiff(id1,id2)
test <- data[id3,]


```


## Question 2:
Fit decision trees to the training data so that you change the default settings
one by one (i.e. not simultaneously):
a. Decision Tree with default settings.
b. Decision Tree with smallest allowed node size equal to 7000.
c. Decision trees minimum deviance to 0.0005.
and report the misclassification rates for the training and validation data.
Which model is the best one among these three? Report how changing the
deviance and node size affected the size of the trees and explain why.

```{r, echo=FALSE, warning=FALSE}

library(tree)

#Misclassification
missclass=function(X){
  n=sum(X)
  a = sum(diag(X))/n
  return(1-a)
}

#Decision Tree with default settings.
fit=tree(y~., data=train)
yfit = predict(fit, newdata=train, type="class")
amatrix = table(yfit,train$y)[2:1, 2:1]
paste0("Default settings trees, Training missclassification:", missclass(amatrix))

Yfit = predict(fit, newdata=validation, type="class")
amatrix_2 = table(validation$y,Yfit)[2:1, 2:1]
paste0("Default settings trees, Validation missclassification:", missclass(amatrix_2))
plot(fit)
text(fit, pretty=0)
summary(fit)

#Decision Tree with smallest allowed node size equal to 7000.
fitb=tree(y~., data=train, minsize=7000)
Yfitb = predict(fitb, newdata=train, type="class")
bmatrix = table(train$y,Yfitb)[2:1, 2:1]
paste0("Smallest allowed node size trees, Training missclassification:", missclass(bmatrix))

Yfitb = predict(fitb, newdata=validation, type="class")
bmatrix_2 = table(validation$y,Yfitb)[2:1, 2:1]
paste0("Smallest allowed node size trees, Validation missclassification:", missclass(bmatrix_2))
plot(fitb)
text(fitb, pretty=0)
summary(fitb)


#Decision trees minimum deviance to 0.0005.
fitc=tree(y~., data=train, mindev=0.0005)
Yfitc = predict(fitc, newdata=train, type="class")
cmatrix = table(train$y,Yfitc)[2:1, 2:1]
paste0("Deviance trees, Training missclassification:", missclass(cmatrix))

Yfitc = predict(fitc, newdata=validation, type="class")
cmatrix_2 = table(validation$y,Yfitc)[2:1, 2:1]
paste0("Deviance trees, Validation missclassification:", missclass(cmatrix_2))
plot(fitc)
text(fitc)
summary(fitc)
```

**Answer** 
Decision trees minimum deviance to 0.0005 gave the lowest missclassification rate for
train data. Lowest validation error was given by default setting tree and tree with smallest allowed node.
In addition both settings gave same missclassification error for both validation and train data.
As it can be seen in the figure and summary. Min deviance has highest number of terminal nodes, equal to 122.
This resulted in a biggest tree size.
Thereafter, the tree with default settings has 6 terminal nodes and is 2nd largest.
Lastly, min node size has 5 terminal nodes and is the smallest tree.
It is important to examine both figure and number of terminal nodes as the tree can be unbalanced
and have increased depth. The size of tree of min deviance can be due to minimal number of error of each node.
This rule forces the tree to increase in the size and have more nodes.
The opposite could be find with min node size, as all leaves have required number of size
and it can be seen that is why it is a smallest tree.


## Question 3.
Use training and validation sets to choose the optimal tree depth in the
model 2c: study the trees up to 50 leaves. Present a graph of the dependence
of deviances for the training and the validation data on the number of leaves
and interpret this graph in terms of bias-variance tradeoff. Report the
optimal amount of leaves and which variables seem to be most important for
decision making in this tree. Interpret the information provided by the tree
structure (not everything but most important findings).

```{r, echo=FALSE}
trainScore=rep(0,50)
validationScore=rep(0,50)
for(i in 2:50) {
  prunedTree=prune.tree(fitc,best=i)
  pred=predict(prunedTree, newdata=validation, type="tree")
  trainScore[i]=deviance(prunedTree)
  validationScore[i]=deviance(pred)
}
plot(2:50, trainScore[2:50], type="b", col="red",ylim=c(8000,12000), xlab="Leaves",ylab="Deviance")
points(2:50, validationScore[2:50], type="b", col="blue")

optimal_tree_depths = which.min(validationScore[2:50])+1
#Added +1 because the second element is counted as 1
#it takes 42th element when the list is from 2 to 50. 

prune.tree(fitc,best=optimal_tree_depths)

```

**Answer:**
For bias-variance trade off, it can be seen x-axis as model complexity. For higher number of leaves, the 
model get more complex. Deviance, is defined as measure of goodness of fit and can be used
as an error. As model gets more complex, the deviance decreases. Although, it holds the same level
at the optimal number of leaves which is around 22 leaves. Thereafter the blue points corresponding for
validation, slowly increases. Therefore, it can be seen that bias decreases up till leaves 22 which is the optimal amount of leaves. Before leaves 22, the model is underfitted and after it is overfitted. 

The most important variable is **poutcome** as it is one of the first nodes that is best at separating
the tree and classes. Thereafter, by looking at the frequency of the nodes variables **month** and **pdays**
are frequently used to split the classes.

By the provided tree it can be seen that the tree is not balanced, most of the nodes are going through
one side and the depth of the tree is therefore deeper. It can be also seen that if **poutcome** is "success"
the probability is around higher than 50% to classify it as yes. The opposite side with most number of observations is mostly classified as no if **poutcome** is defined as failure, other and unknown.

## Question 4
Estimate the confusion matrix, accuracy and F1 score for the test data by
using the optimal model from step 3. Comment whether the model has a
good predictive power and which of the measures (accuracy or F1-score)
should be preferred here.
```{r, echo=FALSE}
best_tree=prune.tree(fitc,best=optimal_tree_depths)
pred=predict(best_tree, newdata=test, type="class")

best_matrix = table(test$y,pred)[2:1, 2:1]

best_matrix

#Accuracy
accuracy=function(X){
  TP = X[1,1]
  TN = X[2,2]
  P = sum(X[1,1:2])
  N = sum(X[2,1:2])
  return((TP+TN)/(P+N))
}
paste0("Accuracy of the model is equal to:", accuracy(best_matrix))


f1 = function(X){
  recall = X[1,1]/sum(X[1,1:2])
  precision = X[1,1]/(X[1,1]+X[2,1])
  return((2*precision*recall)/(precision+recall))
}
paste0("F1 score of the model is equal to:", f1(best_matrix))

```

**Answer** 
For F1, the score should be between 0 to 1 and higher score reflects over better
predictive power. Then the F1 score of 0.22455 can be seen as a bad result. 
Because F1 formula ignores TN, where most of predictions were made it can be quite misleading.
Therefore, F1 formula depends mostly on how imbalanced the data is of TP. 
For accuracy, it shows the percentage of correctness and score of 0.89103 can be seen as quite high.
The preferred measure depends on the goal of the prediction and on the data. But
the preferred method is accuracy as it checks TP and TN.


## Question 5
Perform a decision tree classification of the test data with the following loss
matrix ..., and report the confusion matrix for the test data. Compare the results with
the results from step 4 and discuss how the rates has changed and why.

```{r, echo=FALSE, warning=FALSE}
library(rpart)
loss_matrix = matrix(c(0,5,1,0), nrow=2,byrow=TRUE)
fit = rpart(y~., data=train, method="class",parms=list(loss=loss_matrix))
fit_3_5 = predict(fit, newdata=test, type="class")
matrix_3_5= table(test$y,fit_3_5)[2:1, 2:1]
matrix_3_5
f1(matrix_3_5)
accuracy(matrix_3_5)

```

**Answer**
F1, has NaN values as most of the yes prediction are now 0. 
The accuracy went from 0.89103 to 0.88315, as all values from yes prediction,
moved to the no prediction column. 
As it was described earlier, F1 ignores TN, but most of the calculations
are done on yes column, which for this assignment are 0.
For the accuracy as only TN and FN exists, the results are therefore 
TN/FN.

## Question 6
Use the optimal tree and a logistic regression model to classify the test data by
using the following principle: ... Compute the TPR and FPR values for the
two models and plot the corresponding ROC curves. Conclusion? Why precisionrecall curve could be a better option here?

```{r, warning=FALSE,echo=FALSE,results=FALSE}
library(ggplot2)


TPR = function(X){
  print(X)
  TP = X[1,1]
  P = sum(X[1,1:2])
  return(TP/P)
}

FPR = function(X){
  print(X)
  FP = X[2,1]
  N = sum(X[2,1:2])
  return(FP/N)
}

pi = seq(0.05,0.95,0.05)

#Logistic regression 
fit_log_reg=glm(y~., data=train, family = "binomial")
log_pred=predict(fit_log_reg, newdata=test, type="response")

#Optimal tree
best_tree=prune.tree(fitc,best=optimal_tree_depths)
tree_pred=predict(best_tree, newdata=test)

tree_df =  data.frame("TPR_Tree","FPR_Tree")
logistic_reg_df = data.frame("Pi","TPR_Logistic","FPR_Logistic")

colnames(tree_df) = c("TPR_Tree","FPR_Tree")
colnames(logistic_reg_df) = c("Pi","TPR_Logistic","FPR_Logistic")


k = 1
for (i in pi){
  logistic_reg = ifelse(log_pred>i, "yes", "no")
  optimal_tree = ifelse(tree_pred[,2]<i, "no", "yes")
  
  level = sort(union(test$y, optimal_tree))
  tree_tpr_matrix = TPR(table(factor(test$y,levels=level),factor(optimal_tree,levels=level))[2:1, 2:1])
  tree_fpr_matrix = FPR(table(factor(test$y,levels=level),factor(optimal_tree,levels=level))[2:1, 2:1])
  tree_df[k,] = c(tree_tpr_matrix,tree_fpr_matrix)
  logistic_reg_df[k,] =c(i,TPR(table(test$y,logistic_reg)[2:1, 2:1]),FPR(table(test$y,logistic_reg)[2:1, 2:1]))
  k=k+1
}

results = cbind(logistic_reg_df,tree_df)


plot(tree_df$FPR_Tree,tree_df$TPR_Tree,type="b", col="red", xlab="FPR",ylab="TPR",)
points(logistic_reg_df$FPR_Logistic,logistic_reg_df$TPR_Logistic,type="b",col="blue")

```

**Answer**
The optimal tree model as red line, performs better than logistic regression in the ROC graph.
Although, both of the models have similar results. There is a delay in FPR, as the values go from around 0.15
to 1. Meanwhile for TPR the values go quickly from 0.4 to 0.9 or 1.

As it was mentioned earlier there is imbalance in the data, therefore precision-recall curve
may give a better overview of the model's predictive power.
